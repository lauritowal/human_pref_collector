{
    "item_type": "proposal",
    "title": "Collaborative AI Counters Hate",
    "descriptions": [
        "Here is a 267-word abstract for the grant proposal:\n\nTitle: Collaborative AI Counters Hate\n\nThe rapid proliferation of online hate speech and disinformation poses a significant threat to social cohesion, democratic values, and human dignity. Current AI-assisted moderation approaches are often inadequate, lacking cultural contextualization and procedural guidelines, and relying on limited and biased training datasets. The Collaborative AI Counters Hate project addresses these challenges through an innovative, bottom-up coding approach that brings together fact-checkers, AI developers, and academic intermediaries.\n\nOur project, grounded in the AI4Dignity model, aims to develop a global comparative framework for AI-assisted solutions, a community-based classification approach, and a collaborative toolkit for inclusive and effective speech moderation. Our goals are fourfold: to improve AI-assisted speech moderation, develop an open-access toolkit, set procedural benchmarks, and operationalize the \"human in the loop\" principle. By creating inclusive training datasets and fostering collaboration between stakeholders, we will develop a more nuanced and effective approach to addressing online hate speech and disinformation.\n\nUltimately, our project seeks to promote dignity, respect, and inclusivity in online spaces, and to provide a model for responsible AI development and deployment. By supporting this project, you will be contributing to the creation of a safer, more equitable online environment, and advancing the responsible use of AI for social good.",
        "Here is a possible abstract for the grant proposal:\n\nTitle: Collaborative AI Counters Hate\n\nThe proliferation of online hate speech and disinformation poses a significant threat to social cohesion and democratic values. Current AI-assisted moderation approaches often struggle to effectively address these issues, citing challenges related to data quality, scope, and inclusivity, as well as a lack of procedural guidelines and cultural contextualization. The Collaborative AI Counters Hate project proposes an innovative solution to these challenges through a collaborative bottom-up coding approach. Our AI4Dignity project model will bring together fact-checkers, AI developers, and academic intermediaries to develop a global comparative framework for AI-assisted solutions, a community-based classification approach, and open access toolkit. The project aims to improve AI-assisted speech moderation, set procedural benchmarks, operationalize the \"human in the loop\" principle, and create inclusive training datasets. By tackling the complex issues of online hate speech and disinformation, this project seeks to promote a safer and more inclusive online environment, ultimately contributing to the preservation of human dignity and well-being.",
        "Here is a 267-word abstract for the grant proposal:\n\nTitle: Collaborative AI Counters Hate\n\nThe proliferation of online hate speech and disinformation poses a significant threat to social cohesion, democratic values, and individual well-being. Current AI-assisted moderation approaches are often inadequate, hindered by limited, biased, and culturally insensitive training datasets. To address these challenges, the Collaborative AI Counters Hate project proposes a groundbreaking, collaborative, and community-driven approach to develop innovative AI-assisted solutions for extreme speech moderation.\n\nOur project, grounded in the AI4Dignity model, will establish a global comparative framework for AI-assisted solutions, leveraging a community-based classification approach that engages fact-checkers, AI developers, and academic intermediaries. This collaborative effort will improve AI-assisted speech moderation by developing open access toolkits, setting procedural benchmarks, and operationalizing the \"human in the loop\" principle. Our goal is to create inclusive training datasets that reflect diverse cultural contexts and nuances.\n\nBy tackling the root causes of AI-assisted moderation challenges, our project aims to mitigate the spread of online hate speech and disinformation. We will develop a comprehensive, evidence-based framework that prioritizes procedural guidelines, cultural contextualization, and community engagement. Our proposed solution has the potential to significantly enhance the quality, scope, and inclusivity of AI-assisted moderation, ultimately promoting a safer and more respectful online environment."
    ],
    "origin": "LLM",
    "llm_engine": "together-meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
    "generation_prompt_uid": "9eb6ebceef3a85317a679b429307ccf0",
    "generation_prompt_nickname": "from_json_details",
    "generation_prompt_text": "Write an abstract for a grant proposal based on the following details provided in JSON format. The JSON includes the title and key characteristics of the proposed project.\n\nPlease limit the response to 267 words or less.\n\n---\n\n**Description:**\n\n{'proposal_name': 'Collaborative AI Counters Hate', 'proposal_details': {'description': 'Developing an innovative solution of collaborative bottom-up coding to address AI-assisted extreme speech moderation challenges.', 'challenges': ['Quality, scope, and inclusivity of training data sets', 'Lack of procedural guidelines and cultural contextualization'], 'solutions': ['Global comparative framework in AI-assisted solutions', 'Community-based classification approach', 'Collaboration between fact-checkers, AI developers, and academic intermediaries'], 'project_model': 'AI4Dignity', 'goals': ['Improve AI-assisted speech moderation', 'Develop open access toolkit', 'Set procedural benchmarks', \"Operationalize 'the human in the loop' principle\", 'Create inclusive training datasets'], 'target_issues': ['Online hate speech', 'Disinformation']}}"
}