{
    "item_type": "proposal",
    "title": "Collaborative AI Counters Hate",
    "descriptions": [
        {
            "proposal_name": "Collaborative AI Counters Hate",
            "proposal_details": {
                "description": "Developing an innovative solution of collaborative bottom-up coding to address AI-assisted extreme speech moderation challenges.",
                "challenges": [
                    "Quality, scope, and inclusivity of training data sets",
                    "Lack of procedural guidelines and cultural contextualization"
                ],
                "solutions": [
                    "Global comparative framework in AI-assisted solutions",
                    "Community-based classification approach",
                    "Collaboration between fact-checkers, AI developers, and academic intermediaries"
                ],
                "project_model": "AI4Dignity",
                "goals": [
                    "Improve AI-assisted speech moderation",
                    "Develop open access toolkit",
                    "Set procedural benchmarks",
                    "Operationalize 'the human in the loop' principle",
                    "Create inclusive training datasets"
                ],
                "target_issues": [
                    "Online hate speech",
                    "Disinformation"
                ]
            }
        }
    ],
    "origin": "LLM",
    "llm_engine": "gpt-4-1106-preview",
    "generation_prompt_uid": "bb7c9ec8310581e62eab0cd004a69b61",
    "generation_prompt_nickname": "jsonify_key_details_proposal",
    "generation_prompt_text": "Extract and present the key details from this grant proposal abstract in valid JSON format. Keep array structures simple and flat where possible. Focus only on capturing the concrete features, characteristics, and data points - exclude any narrative text or prose descriptions. The response should contain exactly one item in the 'descriptions' array!\n\n---\n\n**Title:**\n\nCollaborative AI Counters Hate\n\n**Description:**\n\nOnline hate speech and disinformation have emerged as a major problem for democratic societies worldwide. Governments, companies and civil society groups have responded to this phenomenon by increasingly turning to Artificial Intelligence (AI) as a tool that can detect, decelerate and remove online extreme speech. However, such efforts confront many challenges. One of the key challenges is the quality, scope, and inclusivity of training data sets. The second challenge is the lack of procedural guidelines and frameworks that can bring cultural contextualization to these systems. Lack of cultural contextualization has resulted in false positives, over-application and systemic bias. The ongoing ERC project has identified the need for a global comparative framework in AI-assisted solutions in order to address cultural variation, since there is no catch-all algorithm that can work for different contexts. Following this, the proposed project will address major challenges facing AI assisted extreme speech moderation by developing an innovative solution of collaborative bottom-up coding. The model, “AI4Dignity”, moves beyond keyword-based detection systems by pioneering a community-based classification approach. It identifies fact-checkers as critical human interlocutors who can bring cultural contextualization to AI-assisted speech moderation in a meaningful and feasible manner. The project will develop a replicable process model that will enable collaboration between fact-checkers, AI developers and academic intermediaries in a facilitated event space. The project will develop an open access toolkit for the adoption of this model in different locations. AI4Dignity will be a significant step towards setting procedural benchmarks to operationalize “the human in the loop” principle and bring inclusive training datasets for AI systems tackling urgent issues of digital hate and disinformation."
}