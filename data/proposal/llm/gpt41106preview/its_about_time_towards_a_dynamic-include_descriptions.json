{
    "item_type": "proposal",
    "title": "It's about time: Towards a dynamic account of natural vision.",
    "descriptions": [
        "Abstract:\n\nThis grant proposal outlines the development of a novel framework for understanding the visual system, entitled TIME (Temporal Integration and Multiscale Exploration), which seeks to revolutionize the way we study and model vision. The prevailing approach to higher-level vision research has predominantly focused on bottom-up categorization, which does not adequately represent the complexity of how the brain processes visual information in a dynamic and integrative manner. TIME challenges this perspective by proposing a shift towards investigating vision as an active, semantic comprehension process that unfolds over various timescales and is intrinsically linked with information sampling.\n\nThe proposed work program is an interdisciplinary amalgamation of cutting-edge non-invasive brain imaging, advanced multivariate analysis techniques, and the creation of a new bio-inspired deep learning framework for active vision. Participants will engage with a vast array of human-annotated natural scenes while their brain activity is monitored, allowing for an unprecedented exploration of how semantic understanding emerges and evolves as the brain actively gathers and synthesizes visual information.\n\nBy bridging experimentation with computational modelling, TIME aims to decipher the temporal and spatial dimensions of visual semantic integration within the brain. The research will provide a more accurate representation of vision as a continuous, contextually-driven decision-making process, significantly deviating from existing models that view vision as a passive, moment-to-moment categorization task.\n\nThe outcomes of this research are anticipated to lead to a fundamental paradigm shift in the study of vision, offering profound insights into the neural underpinnings of visual processing. Moreover, it promises to enhance the congruence between biological perception and artificial vision systems, fostering advancements in both cognitive neuroscience and machine learning. This transformative approach has the potential to redefine our understanding of vision in more ecologically valid and complex scenarios."
    ],
    "origin": "LLM",
    "llm_engine": "gpt-4-1106-preview",
    "generation_prompt_uid": "9ba94410b311c98d036a7cc2f62b8471",
    "generation_prompt_nickname": "include_descriptions",
    "generation_prompt_text": "Write an abstract for a grant proposal. Use the existing description below as a guideline, matching it roughly in quality and level of detail. Do not include information not available in the description below. Do not directly plagiarize the description below.\n\nPlease limit the response to 281 words or less.\n\n---\n\n**Description:**\n\nThe visual world around us is a source of rich semantic information that guides our higher-level cognitive processes and actions. To tap into this resource, the brain?s visual system engages in complex, intertwined computations to actively sample, extract, and integrate information across space and time. Surprisingly however, the integrative nature of vision hardly plays a role in the way we approach it in experimentation and computational modelling. Instead, higher-level vision is commonly treated as a largely bottom-up categorization process. TIME proposes a new approach. It will allow us to study vision in a more natural setting and as a process that is (a) geared towards semantic understanding instead of label-based categorisation, (b) naturally intertwined with active information sampling and (c) expanding across multiple timeframes, including network dynamics that unfold within and across eye fixations. This will be accomplished by an ambitious, three-step work program that combines cutting-edge non-invasive human brain imaging performed while participants visually explore tens of thousands of rich human-annotated natural scenes, the development of novel multivariate analysis techniques, and large-scale computational modelling using a new bio-inspired deep learning framework for active vision that closes the sensory-motor loop. Using this interdisciplinary approach, TIME will establish, for the first time, when, where, and how visual semantic understanding emerges in the brain as it actively samples and integrates information from the world in a continuously updating and dynamic decision process. These ground-breaking developments both in experimentation and deep neural network modelling build towards a fundamental paradigm shift in how we study, model, and understand vision, yielding new insights into its complex neural processes operating in more natural, ecologically valid conditions, as well as a closer alignment between biological and synthetic vision.",
    "include_year": false
}