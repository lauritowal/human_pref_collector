{
    "item_type": "proposal",
    "title": "A computational approach to early language bootstrapping",
    "descriptions": [
        "Abstract:\n\nThis grant proposal outlines a multifaceted research initiative aimed at unraveling the mystery behind the parallel acquisition of phonemes, words, and phonological rules by infants during their critical first year of language development. Leveraging the synergies between Machine Learning and Automatic Speech Recognition, the project seeks to construct a comprehensive model of this complex learning process. The model will be rigorously tested against large spontaneous speech databases from Japanese, French, and Dutch languages and will be further validated through empirical infant studies employing behavioral tests, electroencephalograms (EEGs), and functional near-infrared spectroscopy (fNIRS).\n\nThe proposed research is divided into four interconnected subprojects, each addressing a key aspect of early language acquisition. The first subproject examines the encoding of speech by exploring various features from fine-grained to coarse-grained levels, paralleling this with the development of speech coding in infants aged 6, 9, and 12 months. The second focuses on lexicon development, enhancing word segmentation algorithms for raw speech to predict the emergence of an initial, expansive lexicon in infants that differs from that of adults. The third subproject tackles the complexity of phoneme production through a predictive model of coarticulation, aiming to understand the infant's ability to perform reverse coarticulation. Finally, the fourth subproject aims to integrate these components, iteratively refining the representations to better align with adult speech and contextual rules.\n\nThe project's outcomes will be numerically evaluated against both adult-directed and infant-directed speech databases, with comparisons to top-tier supervised phoneme recognizers. The validity of the model's predictions will be tested through experiments with infants learning artificial languages and through a longitudinal study, providing unprecedented insights into the natural mechanisms of language acquisition in the first year of life."
    ],
    "origin": "LLM",
    "llm_engine": "gpt-4-1106-preview",
    "generation_prompt_uid": "b084c35a8129f3478fc6faec0335d8a7",
    "generation_prompt_nickname": "include_descriptions",
    "generation_prompt_text": "Write an abstract for a grant proposal. Use the existing description below as a guideline, matching it roughly in quality and level of detail. Do not include information not available in the description below. Do not directly plagiarize the description below.\n\nPlease limit the response to 302 words or less.\n\n---\n\n**Description:**\n\nDuring their first year of life, infants become attuned to the phonemes, words and phonological rules of their language, with little or no adult supervision. After 30 years of accumulated experimental results, we are still lacking an account for the puzzling fact that these 3 interdependent components of language are acquired not sequentially, but in parallel. Drawing tools from Machine Learning and Automatic Speech Recognition, we construct a model of this early process, test it on 2 large spontaneous speech databases (Japanese, French and Dutch) and test its predictions in infants using behavioral, EEGs and fNIRS techniques. 1. Coding. We study different ways of defining coding features for speech, from fine-grained to coarse grained, in view of the automatic discovery of a hierarchy of linguistic units. We compare this with a systematic study of the units of speech coding as they unfold in 6, 9 and 12 month old infants.. 2. Lexicon. Infants recognize some words before they know the phonemes of their language; we modify existing word segmentation algorithms so they can work on raw speech. We test the unique prediction that infants start with a large lexicon thatâ€™s quite different from the adult one. 3. Rules. Phonemes are produced as overlapping, coarticulated gestures. To untangle these context effects, we use a predictive model of coarticulation in auditory space and invert it. We test when and how infants perform reverse coarticulation. 4. Integration. The above subprojects provide only an initial bootstrapping into approximate phonemes, words, and contextual rules. We show how to iteratively integrate these approximate representations to derive better ones. The outcome will be numerically assessed on an adult directed and infant directed speech database, and compared to those of to state-of-the-art supervized phoneme recognizers. The predictions will be tested in infants learning artificial languages and in a longitudinal study.",
    "include_year": false
}