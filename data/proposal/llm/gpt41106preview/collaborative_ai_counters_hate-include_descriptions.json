{
    "item_type": "proposal",
    "title": "Collaborative AI Counters Hate",
    "descriptions": [
        "**Abstract:**\n\nThe proliferation of online hate speech and disinformation poses a significant threat to the fabric of democratic societies, necessitating effective countermeasures. AI-based moderation tools have become popular solutions but face challenges including inadequate training data and the absence of nuanced cultural contextualization, which can lead to over-censorship and systemic biases. Addressing these challenges, our proposed project, \"AI4Dignity,\" aims to innovate AI-assisted moderation of extreme speech by introducing a collaborative, community-driven classification system. This approach leverages the expertise of fact-checkers as key players in enhancing the cultural relevance of AI moderation, thus reducing false positives and aligning with diverse societal norms.\n\nThe project intends to create a global comparative framework to cater to cultural variations in online speech, recognizing that a universal algorithmic solution is unattainable. AI4Dignity will pioneer a bottom-up coding model that facilitates cooperation among fact-checkers, AI developers, and academic advisors, culminating in a facilitated event space that fosters mutual understanding and knowledge sharing. A key deliverable of AI4Dignity is an open-access toolkit designed to enable the implementation of this collaborative model across various geopolitical landscapes.\n\nBy setting procedural benchmarks and incorporating \"the human in the loop\" principle, AI4Dignity will significantly enhance the inclusiveness and accuracy of training datasets for AI systems. Our project promises to be a transformative step in mitigating the impact of digital hate and disinformation, promoting a more respectful and informed online discourse."
    ],
    "origin": "LLM",
    "llm_engine": "gpt-4-1106-preview",
    "generation_prompt_uid": "c9b866364e5c908f2c614c803ba279eb",
    "generation_prompt_nickname": "include_descriptions",
    "generation_prompt_text": "Write an abstract for a grant proposal. Use the existing description below as a guideline, matching it roughly in quality and level of detail. Do not include information not available in the description below. Do not directly plagiarize the description below.\n\nPlease limit the response to 267 words or less.\n\n---\n\n**Description:**\n\nOnline hate speech and disinformation have emerged as a major problem for democratic societies worldwide. Governments, companies and civil society groups have responded to this phenomenon by increasingly turning to Artificial Intelligence (AI) as a tool that can detect, decelerate and remove online extreme speech. However, such efforts confront many challenges. One of the key challenges is the quality, scope, and inclusivity of training data sets. The second challenge is the lack of procedural guidelines and frameworks that can bring cultural contextualization to these systems. Lack of cultural contextualization has resulted in false positives, over-application and systemic bias. The ongoing ERC project has identified the need for a global comparative framework in AI-assisted solutions in order to address cultural variation, since there is no catch-all algorithm that can work for different contexts. Following this, the proposed project will address major challenges facing AI assisted extreme speech moderation by developing an innovative solution of collaborative bottom-up coding. The model, “AI4Dignity”, moves beyond keyword-based detection systems by pioneering a community-based classification approach. It identifies fact-checkers as critical human interlocutors who can bring cultural contextualization to AI-assisted speech moderation in a meaningful and feasible manner. The project will develop a replicable process model that will enable collaboration between fact-checkers, AI developers and academic intermediaries in a facilitated event space. The project will develop an open access toolkit for the adoption of this model in different locations. AI4Dignity will be a significant step towards setting procedural benchmarks to operationalize “the human in the loop” principle and bring inclusive training datasets for AI systems tackling urgent issues of digital hate and disinformation.",
    "include_year": false
}