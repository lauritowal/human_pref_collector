{
    "item_type": "proposal",
    "title": "FARE_AUDIT: Fake News Recommendations - an Auditing System of Differential Tracking and Search Engine Results",
    "descriptions": [
        "**Title: Enhancing Transparency in Online Information Retrieval**\n\n**Abstract:**\n\nThe proliferation of disinformation online poses a significant threat to democratic societies, as citizens increasingly rely on internet sources for information. Algorithms driving search engines and social media platforms can create \"information bubbles\" by filtering out diverse perspectives and promoting low-credibility content. While efforts have been made to combat disinformation on social media, the impact of search engines remains understudied. This project aims to develop a novel auditing tool to investigate and mitigate the spread of disinformation via search engines. Our objectives are threefold: 1) to analyze the influence of browsing history on search results, 2) to design a system for detecting new disinformation in real-time, and 3) to simulate alternative search results to breach information bubbles. Utilizing web-crawlers, our approach prioritizes user privacy and anticipates emerging tracking technologies. By providing a tool for organizations to monitor and detect disinformation, we aim to increase public awareness of the role of search engines in disinformation spread and promote a more informed and critically thinking citizenry."
    ],
    "origin": "LLM",
    "llm_engine": "together-meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "generation_prompt_uid": "e04f5832a509b600d91022c867ff7563",
    "generation_prompt_nickname": "include_descriptions",
    "generation_prompt_text": "Write an abstract for a grant proposal. Use the existing description below as a guideline, matching it roughly in quality and level of detail. Do not include information not available in the description below. Do not directly plagiarize the description below.\n\nPlease limit the response to 289 words or less.\n\n---\n\n**Description:**\n\nThe spread of disinformation is a serious problem that impacts social structure and threatens democracies worldwide. Citizens increasingly rely on (dis)information available online, either somewhat passively, through social media feeds, or actively, by using search engines and specific websites. In both scenarios, algorithms filter and select displayed information according to the users’ past preferences. There is a real risk that algorithms might reinforce the user’s beliefs and create (dis)information bubbles, by offering less divergent views, or even directing them to low-credibility content. For these reasons, serious efforts have been made to identify and remove “fake-news” websites and minimize the spread of disinformation on social media, but we have not witnessed equivalent attempts to understand and curtail the role of search engines. FARE_AUDIT addresses this imbalance and offers an innovative tool to audit search engines that can be broadly used. It will help to 1) better understand how browsing history influences search engine results, particularly the likelihood of being directed to disinformation, 2) create a system that democracy-promoting institutions and concerned citizens can use to identify new disinformation, in near real-time, and 3) breach information bubbles by simulating how search results would be different if users had a different online profile. By relying on web-crawlers, our tool is privacy-protecting and does not require any real user data. Moreover, the proposed system anticipates the announced shift from cookie-tracking to fingerprinting and takes advantage of the expected small time overlap between both systems to learn from both and broaden its scope. Overall, we expect this novel tool to have a meaningful social impact by increasing public awareness of the role of search engines on disinformation spread, and by equipping organizations with a tool to detect and monitor disinformation, especially in political contexts.",
    "include_year": false
}