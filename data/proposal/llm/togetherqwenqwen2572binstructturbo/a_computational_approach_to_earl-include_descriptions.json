{
    "item_type": "proposal",
    "title": "A computational approach to early language bootstrapping",
    "descriptions": [
        "**Abstract:**\n\nThe acquisition of language in infants, particularly the parallel development of phonemes, words, and phonological rules, remains a significant mystery in cognitive science. This project seeks to address this gap by integrating advances in Machine Learning and Automatic Speech Recognition to develop a comprehensive model of early language acquisition. We will test this model using large spontaneous speech databases from Japanese, French, and Dutch, and validate its predictions through behavioral, EEG, and fNIRS studies with infants. The project is structured into four subprojects: 1) Coding, where we explore various coding features for speech, from fine-grained to coarse-grained, to understand the automatic discovery of linguistic units in infants at 6, 9, and 12 months; 2) Lexicon, focusing on the modification of word segmentation algorithms to operate on raw speech and predicting that infants begin with a lexicon distinct from adults; 3) Rules, using a predictive model of coarticulation to understand how infants disentangle overlapping phonemes; and 4) Integration, demonstrating how initial approximate representations of phonemes, words, and rules can be iteratively refined. The outcomes will be quantitatively evaluated on both adult-directed and infant-directed speech databases and compared to state-of-the-art supervised phoneme recognizers. Additionally, the model's predictions will be tested in infants learning artificial languages and through a longitudinal study, providing a robust framework for understanding the early stages of language acquisition."
    ],
    "origin": "LLM",
    "llm_engine": "together-Qwen/Qwen2.5-72B-Instruct-Turbo",
    "generation_prompt_uid": "b084c35a8129f3478fc6faec0335d8a7",
    "generation_prompt_nickname": "include_descriptions",
    "generation_prompt_text": "Write an abstract for a grant proposal. Use the existing description below as a guideline, matching it roughly in quality and level of detail. Do not include information not available in the description below. Do not directly plagiarize the description below.\n\nPlease limit the response to 302 words or less.\n\n---\n\n**Description:**\n\nDuring their first year of life, infants become attuned to the phonemes, words and phonological rules of their language, with little or no adult supervision. After 30 years of accumulated experimental results, we are still lacking an account for the puzzling fact that these 3 interdependent components of language are acquired not sequentially, but in parallel. Drawing tools from Machine Learning and Automatic Speech Recognition, we construct a model of this early process, test it on 2 large spontaneous speech databases (Japanese, French and Dutch) and test its predictions in infants using behavioral, EEGs and fNIRS techniques. 1. Coding. We study different ways of defining coding features for speech, from fine-grained to coarse grained, in view of the automatic discovery of a hierarchy of linguistic units. We compare this with a systematic study of the units of speech coding as they unfold in 6, 9 and 12 month old infants.. 2. Lexicon. Infants recognize some words before they know the phonemes of their language; we modify existing word segmentation algorithms so they can work on raw speech. We test the unique prediction that infants start with a large lexicon thatâ€™s quite different from the adult one. 3. Rules. Phonemes are produced as overlapping, coarticulated gestures. To untangle these context effects, we use a predictive model of coarticulation in auditory space and invert it. We test when and how infants perform reverse coarticulation. 4. Integration. The above subprojects provide only an initial bootstrapping into approximate phonemes, words, and contextual rules. We show how to iteratively integrate these approximate representations to derive better ones. The outcome will be numerically assessed on an adult directed and infant directed speech database, and compared to those of to state-of-the-art supervized phoneme recognizers. The predictions will be tested in infants learning artificial languages and in a longitudinal study.",
    "include_year": false
}